sum(is.na(College))
tsize = nrow(College)/2
train_set = sample(1:nrow(College), tsize)
test_set = -train_set
train_lm = lm(Apps~.,College[train_set,])
test_lm = predict(train_lm,College[test_set,])
lm_MSE = mean((test_lm - College[test_set,]$Apps)^2)
lm_MSE
train_matrix = model.matrix(Apps~., College[train_set,])
test_matrix = model.matrix(Apps~., College[test_set,])
grid = 10 ^ seq(10, -2, length=100)
ridge_model = cv.glmnet(train_matrix, College[train_set,"Apps"], alpha=0, lambda=grid, thresh=1e-12)
optimal_lam = ridge_model$lambda.min
optimal_lam
sum(is.na(College))
set.seed(11)
tsize = nrow(College)/2
train_set = sample(1:nrow(College), tsize)
test_set = -train_set
train_lm = lm(Apps~.,College[train_set,])
test_lm = predict(train_lm,College[test_set,])
lm_MSE = mean((test_lm - College[test_set,]$Apps)^2)
lm_MSE
train_matrix = model.matrix(Apps~., College[train_set,])
test_matrix = model.matrix(Apps~., College[test_set,])
grid = 10 ^ seq(10, -2, length=100)
ridge_model = cv.glmnet(train_matrix, College[train_set,"Apps"], alpha=0, lambda=grid, thresh=1e-12)
optimal_lam = ridge_model$lambda.min
optimal_lam
sum(is.na(College))
tsize = nrow(College)/2
train_set = sample(1:nrow(College), tsize)
test_set = -train_set
sum(is.na(College))
set.seed(101)
tsize = nrow(College)/2
train_set = sample(1:nrow(College), tsize)
test_set = -train_set
train_lm = lm(Apps~.,College[train_set,])
test_lm = predict(train_lm,College[test_set,])
lm_MSE = mean((test_lm - College[test_set,]$Apps)^2)
lm_MSE
train_matrix = model.matrix(Apps~., College[train_set,])
test_matrix = model.matrix(Apps~., College[test_set,])
grid = 10 ^ seq(10, -2, length=100)
ridge_model = cv.glmnet(train_matrix, College[train_set,"Apps"], alpha=0, lambda=grid, thresh=1e-12)
optimal_lam = ridge_model$lambda.min
optimal_lam
sum(is.na(College))
set.seed(222)
tsize = nrow(College)/2
train_set = sample(1:nrow(College), tsize)
test_set = -train_set
train_lm = lm(Apps~.,College[train_set,])
test_lm = predict(train_lm,College[test_set,])
lm_MSE = mean((test_lm - College[test_set,]$Apps)^2)
lm_MSE
train_matrix = model.matrix(Apps~., College[train_set,])
test_matrix = model.matrix(Apps~., College[test_set,])
grid = 10 ^ seq(10, -2, length=100)
ridge_model = cv.glmnet(train_matrix, College[train_set,"Apps"], alpha=0, lambda=grid, thresh=1e-12)
optimal_lam = ridge_model$lambda.min
optimal_lam
ridge_predict = predict(ridge_model, s=optimal_lam, newx=test_matrix)
ridge_MSE = mean((College[test_set, "Apps"] - ridge_predict)^2)
ridge_MSE
lasso_model = cv.glmnet(train_matrix, College[train_set,"Apps"], alpha=1, lambda=grid, thresh=1e-12)
optimal_lam = lasso_model$lambda.min
optimal_lam
lasso_predict = predict(lasso_model, s=optimal_lam, newx=test_matrix)
lasso_MSE = mean((College[test_set, "Apps"] - lasso_predict)^2)
lasso_MSE
lasso_coef = coef(lasso_model)
lasso_coef
lasso_model = glmnet(model.matrix(Apps~., data=College), College[, "Apps"], alpha=1)
predict(mod.lasso, s=optimal_lam, type="coefficients")
lasso_model = glmnet(model.matrix(Apps~., data=College), College[, "Apps"], alpha=1)
predict(lasso_model, s=optimal_lam, type="coefficients")
model.matrix(Apps~., College[train_set,])
lasso_predict = predict(lasso_model, s=optimal_lam, newx=test_matrix)
lasso_MSE = mean((College[test_set, "Apps"] - lasso_predict)^2)
lasso_MSE
lasso_predict = predict(lasso_model, s=optimal_lam, newx=test_matrix)
lasso_MSE = mean((College[test_set, "Apps"] - lasso_predict)^2)
lasso_MSE
lasso_coef = coef(lasso_model)
lasso_coef
sum(is.na(College))
set.seed(222)
tsize = nrow(College)/2
train_set = sample(1:nrow(College), tsize)
test_set = -train_set
train_lm = lm(Apps~.,College[train_set,])
test_lm = predict(train_lm,College[test_set,])
lm_MSE = mean((test_lm - College[test_set,]$Apps)^2)
lm_MSE
train_matrix = model.matrix(Apps~., College[train_set,])
test_matrix = model.matrix(Apps~., College[test_set,])
grid = 10 ^ seq(10, -2, length=100)
ridge_model = cv.glmnet(train_matrix, College[train_set,"Apps"], alpha=0, lambda=grid, thresh=1e-12)
optimal_lam = ridge_model$lambda.min
optimal_lam
ridge_predict = predict(ridge_model, s=optimal_lam, newx=test_matrix)
ridge_MSE = mean((College[test_set, "Apps"] - ridge_predict)^2)
ridge_MSE
lasso_model = cv.glmnet(train_matrix, College[train_set,"Apps"], alpha=1, lambda=grid, thresh=1e-12)
optimal_lam = lasso_model$lambda.min
optimal_lam
lasso_predict = predict(lasso_model, s=optimal_lam, newx=test_matrix)
lasso_MSE = mean((College[test_set, "Apps"] - lasso_predict)^2)
lasso_MSE
lasso_coef = coef(lasso_model)
lasso_coef
lasso_coef[lasso_coef!=0]
length(lasso_coef[lasso_coef!=0])
lasso_coef = coef(lasso_model)
length(lasso_coef[lasso_coef!=0])
pcr_model = pcr(Apps~., data = College[train_set,], scale=T, validation="CV")
validationplot(pcr_model, val.type="MSEP")
summary(pcr_model)
pcr_predic = predict(pcr_model, College[test_set,], ncomp=12)
pcr_MSE = mean((College[test_set, "Apps"] - data.frame(pcr_predic))^2)
pcr_MSE
pcr_predic = predict(pcr_model, College[test_set,], ncomp=15)
pcr_MSE = mean((College[test_set, "Apps"] - data.frame(pcr_predic))^2)
pcr_MSE
pcr_predic = predict(pcr_model, College[test_set,], ncomp=17)
pcr_MSE = mean((College[test_set, "Apps"] - data.frame(pcr_predic))^2)
pcr_MSE
pcr_predic = predict(pcr_model, College[test_set,], ncomp=16)
pcr_MSE = mean((College[test_set, "Apps"] - data.frame(pcr_predic))^2)
pcr_MSE
pls_model = plsr(Apps~., data=College[train_set,], scale=T, validation="CV")
validationplot(pls_model, val.type="MSEP")
summary(pls_model)
pls_predic = predict(pls_model, College[test_set,], ncomp=12)
pls_MSE = mean((College[test_set, "Apps"] - data.frame(pls_predic))^2)
pls_MSE
pls_predic = predict(pls_model, College[test_set,], ncomp=5)
pls_MSE = mean((College[test_set, "Apps"] - data.frame(pls_predic))^2)
pls_MSE
pls_predic = predict(pls_model, College[test_set,], ncomp=9)
pls_MSE = mean((College[test_set, "Apps"] - data.frame(pls_predic))^2)
pls_MSE
barplot(c(lm_MSE,ridge_MSE,lasso_MSE,pcr_MSE,pls_MSE),
col="green", names.arg=c("LS", "Ridge", "Lasso", "PCR", "PLS"), main="RMSE")
mean(College$Apps)
sd(College$Apps)
sqrt(pls_MSE)
mean(College$Apps)
barplot(c(lm_MSE,ridge_MSE,lasso_MSE,pcr_MSE,pls_MSE),
col="green", names.arg=c("LS", "Ridge", "Lasso", "PCR", "PLS"), main="RMSE",text(c(lm_MSE,ridge_MSE,lasso_MSE,pcr_MSE,pls_MSE)))
barplot(c(lm_MSE,ridge_MSE,lasso_MSE,pcr_MSE,pls_MSE),
col="green", names.arg=c("LS", "Ridge", "Lasso", "PCR", "PLS"), main="RMSE")
c(lm_MSE,ridge_MSE,lasso_MSE,pcr_MSE,pls_MSE)
set.seed(50)
sum(is.na(Boston))
tsize = nrow(Boston)/2
train_set = sample(1:nrow(Boston), tsize)
test_set = -train_set
pls_model = plsr(crim~., data=Boston[train_set,], scale=T, validation="CV")
validationplot(pls_model, val.type="MSEP")
summary(pls_model)
pls_MSE
pcr_model = pcr(crim~., data = Boston[train_set,], scale=T, validation="CV")
validationplot(pcr_model, val.type="MSEP")
summary(pcr_model)
pcr_predic = predict(pcr_model, Boston[test_set,], ncomp=3)
pcr_MSE = mean((Boston[test_set, "crim"] - data.frame(pcr_predic))^2)
pcr_MSE
set.seed(50)
sum(is.na(Boston))
tsize = nrow(Boston)/2
train_set = sample(1:nrow(Boston), tsize)
test_set = -train_set
pls_model = plsr(crim~., data=Boston[train_set,], scale=T, validation="CV")
validationplot(pls_model, val.type="MSEP")
summary(pls_model)
pls_predic = predict(pls_model, Boston[test_set,], ncomp=2)
pls_MSE = mean((Boston[test_set, "crim"] - data.frame(pls_predic))^2)
pls_MSE
pcr_model = pcr(crim~., data = Boston[train_set,], scale=T, validation="CV")
validationplot(pcr_model, val.type="MSEP")
summary(pcr_model)
pcr_predic = predict(pcr_model, Boston[test_set,], ncomp=3)
pcr_MSE = mean((Boston[test_set, "crim"] - data.frame(pcr_predic))^2)
pcr_MSE
train_matrix = model.matrix(crim~., Boston[train_set,])
test_matrix = model.matrix(crim~., Boston[test_set,])
grid = 10 ^ seq(10, -2, length=100)
ridge_model = cv.glmnet(train_matrix, Boston[train_set,"crim"], alpha=0, lambda=grid)
optimal_lam = ridge_model$lambda.min
ridge_predict = predict(ridge_model, s=optimal_lam, newx=test_matrix)
ridge_MSE = mean((Boston[test_set, "crim"] - ridge_predict)^2)
ridge_MSE
lasso_model = cv.glmnet(train_matrix, Boston[train_set,"crim"], alpha=1, lambda=grid)
optimal_lam = lasso_model$lambda.min
lasso_predict = predict(lasso_model, s=optimal_lam, newx=test_matrix)
lasso_MSE = mean((Boston[test_set, "crim"] - lasso_predict)^2)
lasso_MSE
lasso_coef = coef(lasso_model)
lasso_coef
train_lm = lm(crim~.,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm -tax,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm -tax -indus,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm -tax -indus -chas,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age -ptratio,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age -ptratio -nox,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age -ptratio -nox -zn,Boston[train_set,])
summary(train_lm)
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age -ptratio -nox -zn -dis,Boston[train_set,])
summary(train_lm)
test_lm = predict(train_lm,Boston[test_set,])
lm_MSE = mean((test_lm - Boston[test_set,]$crim)^2)
lm_MSE = mean((test_lm - Boston[test_set,]$crim)^2)
lm_MSE
lm_MSE
c(lm_MSE,ridge_MSE,lasso_MSE,pcr_MSE,pls_MSE
)
barplot(c(pls_MSE,pcr_MSE,ridge_MSE,lasso_MSE,lm_MSE),
col="green", names.arg=c("PLS", "PCR", "Ridge", "Lasso", "BSS"), main="RMSE")
c(pls_MSE,pcr_MSE,ridge_MSE,lasso_MSE,lm_MSE)
plot(lasso_model)
optimal_lam
plot(ridge_model)
optimal_lam
ridge_model = cv.glmnet(train_matrix, Boston[train_set,"crim"], type.measure = "mse", alpha = 0)
plot(ridge_model)
optimal_lam = ridge_model$lambda.min
optimal_lam
ridge_predict = predict(ridge_model, s=optimal_lam, newx=test_matrix)
ridge_MSE = mean((Boston[test_set, "crim"] - ridge_predict)^2)
ridge_MSE
lasso_model = cv.glmnet(train_matrix, Boston[train_set,"crim"], type.measure = "mse")
plot(lasso_model)
optimal_lam = lasso_model$lambda.min
lasso_predict = predict(lasso_model, s=optimal_lam, newx=test_matrix)
lasso_MSE = mean((Boston[test_set, "crim"] - lasso_predict)^2)
lasso_MSE
barplot(c(pls_MSE,pcr_MSE,ridge_MSE,lasso_MSE,lm_MSE),
col="green", names.arg=c("PLS", "PCR", "Ridge", "Lasso", "BSS"), main="RMSE")
c(pls_MSE,pcr_MSE,ridge_MSE,lasso_MSE,lm_MSE)
lasso_coef = coef(lasso_model)
length(lasso_coef[lasso_coef!=0])
lasso_coef[lasso_coef=0]
lasso_coef
lasso_coef = coef(lasso_model)
length(lasso_coef[lasso_coef=0])
length(lasso_coef[lasso_coef==0])
lasso_coef[lasso_coef==0]
lasso_coef = coef(lasso_model)
coef(lasso_model)
pcr_MSE
pcr_model = pcr(Apps~., data = College[train_set,], scale=T, validation="CV")
validationplot(pcr_model, val.type="MSEP")
summary(pcr_model)
pcr_predic = predict(pcr_model, College[test_set,], ncomp=16)
pcr_MSE = mean((College[test_set, "Apps"] - data.frame(pcr_predic))^2)
pcr_MSE
set.seed(50)
sum(is.na(Boston))
tsize = nrow(Boston)/2
train_set = sample(1:nrow(Boston), tsize)
test_set = -train_set
pls_model = plsr(crim~., data=Boston[train_set,], scale=T, validation="CV")
validationplot(pls_model, val.type="MSEP")
summary(pls_model)
pls_predic = predict(pls_model, Boston[test_set,], ncomp=2)
pls_MSE = mean((Boston[test_set, "crim"] - data.frame(pls_predic))^2)
pls_MSE
pcr_model = pcr(crim~., data = Boston[train_set,], scale=T, validation="CV")
validationplot(pcr_model, val.type="MSEP")
summary(pcr_model)
pcr_predic = predict(pcr_model, Boston[test_set,], ncomp=3)
pcr_MSE = mean((Boston[test_set, "crim"] - data.frame(pcr_predic))^2)
pcr_MSE
train_matrix = model.matrix(crim~., Boston[train_set,])
test_matrix = model.matrix(crim~., Boston[test_set,])
ridge_model = cv.glmnet(train_matrix, Boston[train_set,"crim"], type.measure = "mse", alpha = 0)
plot(ridge_model)
optimal_lam = ridge_model$lambda.min
ridge_predict = predict(ridge_model, s=optimal_lam, newx=test_matrix)
ridge_MSE = mean((Boston[test_set, "crim"] - ridge_predict)^2)
ridge_MSE
lasso_model = cv.glmnet(train_matrix, Boston[train_set,"crim"], type.measure = "mse")
plot(lasso_model)
optimal_lam = lasso_model$lambda.min
lasso_predict = predict(lasso_model, s=optimal_lam, newx=test_matrix)
lasso_MSE = mean((Boston[test_set, "crim"] - lasso_predict)^2)
lasso_MSE
train_lm = lm(crim~.,Boston[train_set,])
train_lm = lm(crim~.-lstat,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm -tax,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm -tax -indus,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm -tax -indus -chas,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age -ptratio,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age -ptratio -nox,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age -ptratio -nox -zn,Boston[train_set,])
train_lm = lm(crim~.-lstat -rm -tax -indus -chas -age -ptratio -nox -zn -dis,Boston[train_set,])
test_lm = predict(train_lm,Boston[test_set,])
lm_MSE = mean((test_lm - Boston[test_set,]$crim)^2)
lm_MSE
c(pls_MSE,pcr_MSE,ridge_MSE,lasso_MSE,lm_MSE)
barplot(c(pls_MSE,pcr_MSE,ridge_MSE,lasso_MSE,lm_MSE),
col="green", names.arg=c("PLS", "PCR", "Ridge", "Lasso", "BSS"), main="RMSE")
coef(ridge_model)
carseats_tree = tree(Sales ~ ., data = train_set)
summary(carseats_tree)
plot(carseats_tree)
text(carseats_tree, pretty = 0)
carseats_tree_predict = predict(carseats_tree, test_set)
mean((test_set$Sales - carseats_tree_predict)^2)
set.seed(1)
train = sample(dim(Carseats)[1], dim(Carseats)[1]/2)
train_set = Carseats[train, ]
test_set = Carseats[-train, ]
carseats_tree = tree(Sales ~ ., data = train_set)
summary(carseats_tree)
plot(carseats_tree)
text(carseats_tree, pretty = 0)
carseats_tree_predict = predict(carseats_tree, test_set)
mean((test_set$Sales - carseats_tree_predict)^2)
tree_model = cv.tree(carseats_tree, FUN = prune.tree)
plot(tree_model$size, tree_model$dev, type = "b")
plot(tree_model$k, tree_model$dev, type = "b")
carseats_best = prune.tree(carseats_tree, best = 9)
plot(carseats_best)
text(carseats_best, pretty = 0)
carseats_tree_predict = predict(carseats_best, test_set)
mean((test_set$Sales - carseats_tree_predict)^2)
carseats_bag = randomForest(Sales ~ ., data = train_set, mtry = 10, importance = TRUE)
carseats_bag_predict = predict(carseats_bag, test_set)
mean((test_set$Sales - carseats_bag_predict)^2)
importance(carseats_bag)
carseats_rforest = randomForest(Sales ~ ., data = train_set, mtry = 3, importance = TRUE)
carseats_rforest_predict = predict(carseats_rforest, test_set)
mean((test_set$Sales - carseats_rforest_predict)^2)
importance(carseats_rforest)
train = (1:1000)
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
train_set = Caravan[train, ]
test_set = Caravan[-train, ]
set.seed(342)
caravan_boost = gbm(Purchase ~ ., data = train_set, n.trees = 1000, shrinkage = 0.01, distribution = "bernoulli")
summary(caravan_boost)
caravan_boost_prob = predict(caravan_boost, test_set, n.trees = 1000, type = "response")
caravan_boost_predict = ifelse(caravan_boost_prob > 0.2, 1, 0)
table(test_set$Purchase, caravan_boost_predict)
(34/(137 + 34))*100
caravan_knn = glm(Purchase ~ ., data = train_set, family = binomial)
caravan_knn_prob = predict(caravan_knn, test_set, type = "response")
caravan_knn_predict = ifelse(caravan_knn_prob > 0.2, 1, 0)
table(test_set$Purchase, caravan_knn_predict)
58/(350+58)
beauty <- read.csv("BeautyData.csv")
beauty_lm = lm(CourseEvals~.,beauty)
summary(beauty_lm)
midhouses <- read.csv("MidCity.csv")
midhouses$Nbhd = as.factor(midhouses$Nbhd)
pricing_lm = lm(Price~.,midhouses)
summary(pricing_lm)
midhouses <- read.csv("MidCity.csv")
midhouses$Nbhd = as.factor(midhouses$Nbhd)
pricing_lm = lm(Price~.,midhouses)
summary(pricing_lm)
pricing_lm = lm(Price~.+Nbhd*Brick, midhouses)
summary(pricing_lm)
midhouses <- read.csv("MidCity.csv")
midhouses$Nbhd = ifelse(midhouses$Nbhd == "1"|midhouses$Nbhd == "2", "old", "new")
midhouses$Nbhd = as.factor(midhouses$Nbhd)
pricing_lm = lm(Price~.,midhouses)
summary(pricing_lm)
set.seed(342)
caravan_boost = gbm(Purchase ~ ., data = train_set, n.trees = 1000, shrinkage = 0.01, distribution = "bernoulli")
summary(caravan_boost)
set.seed(342)
caravan_boost = gbm(Purchase ~ ., data = train_set, n.trees = 1000, shrinkage = 0.01, distribution = "bernoulli")
summary(caravan_boost)
setwd("~/Documents/PredictiveModelingPart2/Hw2")
library(tm)
readerPlain = function(fname){
readPlain(elem = list(content = readLines(fname)), id = fname, language = 'en')}
author_dirs = Sys.glob('ReutersC50/C50train/*')
file_list = NULL
labels = NULL
for(author in author_dirs)
{
author_name = substring(author, first=21)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
my_corpus = Corpus(VectorSource(all_docs))
names(my_corpus) = labels
my_corpus = tm_map(my_corpus, content_transformer(tolower))
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers))
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation))
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace))
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM_train = DocumentTermMatrix(my_corpus)
DTM_train
DTM_train = ?removeSparseTerms(DTM_train, 0.97)
DTM_train
X_train = as.matrix(DTM_train)
DTM_train = removeSparseTerms(DTM_train, 0.97)
DTM_train
X_train = as.matrix(DTM_train)
DTM_train = removeSparseTerms(DTM_train, 0.97)
library(tm)
readerPlain = function(fname){
readPlain(elem = list(content = readLines(fname)), id = fname, language = 'en')}
author_dirs = Sys.glob('ReutersC50/C50train/*')
file_list = NULL
labels = NULL
for(author in author_dirs)
{
author_name = substring(author, first=21)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
my_corpus = Corpus(VectorSource(all_docs))
names(my_corpus) = labels
my_corpus = tm_map(my_corpus, content_transformer(tolower))
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers))
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation))
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace))
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM_train = DocumentTermMatrix(my_corpus)
DTM_train
DTM_train = removeSparseTerms(DTM_train, 0.97)
DTM_train
X_train = as.matrix(DTM_train)
author_dirs = Sys.glob('ReutersC50/C50test/*')
file_list = NULL
labels = NULL
for(author in author_dirs)
{
author_name = substring(author, first=20)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
test_corpus = Corpus(VectorSource(all_docs))
names(test_corpus) = labels
test_corpus = tm_map(test_corpus, content_transformer(tolower))
test_corpus = tm_map(test_corpus, content_transformer(removeNumbers))
test_corpus = tm_map(test_corpus, content_transformer(removePunctuation))
test_corpus = tm_map(test_corpus, content_transformer(stripWhitespace))
test_corpus = tm_map(test_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM_test = DocumentTermMatrix(test_corpus)
DTM_test
DTM_test = removeSparseTerms(DTM_test, 0.97)
DTM_test
X_test = as.matrix(DTM_test)
common_words <- intersect(colnames(X_train), colnames(X_test))
ncol(X_test)
ncol(X_train)
X_test <- X_test[,common_words]
X_train <- X_train[,common_words]
ncol(X_test)
ncol(X_train)
smooth_count <- 1/nrow(X_train)
W_train <- X_train + smooth_count
W_train <- rowsum(W_train, group = names(test_corpus))
W_train <- log(W_train/rowSums(W_train))
log_prob <- X_test%*%t(W_train)
Author_pred <- colnames(log_prob)[max.col(log_prob)]
Total_Predicted <- as.integer(Author_pred==names(test_corpus))
Accuracy <- (sum(Total_Predicted)/length(Total_Predicted))*100
Accuracy
Accuracy_per_author <- ((tapply(Total_Predicted, names(test_corpus), sum))/50)*100
subset(Accuracy_per_author, Accuracy_per_author >= 80)
subset(Accuracy_per_author, Accuracy_per_author <= 20)
library(maxent)
Multi_train <- maxent(DTM_train, code_vector = names(my_corpus), use_sgd = TRUE, l1_regularizer = 1.0)
Multi_pred <- predict(Multi_train,DTM_test)
Author_pred <- Multi_pred[,1]
Total_Predicted <- as.integer(Author_pred==names(test_corpus))
Accuracy <- (sum(Total_Predicted)/length(Total_Predicted))*100
Accuracy
library(arules)
baskets <- read.transactions("groceries.txt", format = c("basket"), sep = ',')
grocerie_rules <- apriori(baskets, parameter=list(support=0.009, confidence=0.5))
inspect(grocerie_rules)
library(arules)
baskets <- read.transactions("groceries.txt", format = c("basket"), sep = ',')
grocerie_rules <- apriori(baskets, parameter=list(support=0.009, confidence=0.5))
inspect(grocerie_rules)
