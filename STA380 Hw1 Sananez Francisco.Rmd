---
title: 'STA 380 Homework 1'
author: "Francisco Sananez"
date: "August 6, 2015"
output: word_document
---

# Exploratory Analysis

```{r Libraries, include = FALSE}
# Load used libraries
library(mosaic)
library(foreach)
library(fImport)
library(flexclust)
library(fpc)
library(PerformanceAnalytics)
```

To begin the "georgia2000.csv" data was loaded and saved as Georgia_Counties. Thanks to functions like *head()* and *summary()* one can get a feel of how the data is portrayed and especially see some useful information about each column.

```{r Georgia Summary}
Georgia_Counties <- read.csv("georgia2000.csv") 
head(Georgia_Counties)
summary(Georgia_Counties)
```

For this exercise we are interested in specific columns of this data set, it's the case of "ballots", "votes", "equip", "poor" and "perAA". Essentially we would like to know if there is any relation between "undercounts ratio" ((Ballots-Votes)/ballots) and the equipment used for the voting procedure. First we must calculate such undercounts and plot them against different equipment to see if there is any discrepancies between them.  

```{r Undercounts}
Georgia_Counties$Undercount = (Georgia_Counties$ballots - Georgia_Counties$votes) / Georgia_Counties$ballots
```
```{r Undercount plot, echo=FALSE}
plot(Georgia_Counties$equip,Georgia_Counties$Undercount)
```

We can see with the plot given that the medians throughout all equipments are very close to each other, indicating no huge discrepancy between them. Although it's essential to point out some outliers counties using lever and optical equipment. Now, even though, there are no discrepancies between equipments one might think that counties with higher poor index or minorities are being affected over other counties. In order to display if this is the case, four bar plots were made (one for each equipment) showing the usage of such equipment by number of counties splitted by their poor index.

```{r, echo=FALSE}
par(mfrow=c(2,2))

freq_tab = table(as.factor(Georgia_Counties$poor[Georgia_Counties$equip == "LEVER"]))
barplot(freq_tab[freq_tab>=0], main = "Lever", xlab = "Poor")

freq_tab = table(as.factor(Georgia_Counties$poor[Georgia_Counties$equip == "OPTICAL"]))
barplot(freq_tab[freq_tab>=0], main = "Optical", xlab = "Poor")

freq_tab = table(as.factor(Georgia_Counties$poor[Georgia_Counties$equip == "PAPER"]))
barplot(freq_tab[freq_tab>=0], main = "Paper", xlab = "Poor")

freq_tab = table(as.factor(Georgia_Counties$poor[Georgia_Counties$equip == "PUNCH"]))
barplot(freq_tab[freq_tab>=0], main = "Punch", xlab = "Poor")
```

If we compare this plots to the box plot before we see that minorities are not the only ones being affected by undercount. We might say that undercounts are "higher" (outliers) with optical and lever because of the "higher" complexity it involves against paper or punch, equipment voters have used for longer time.

# Bootstrapping

Now for this second exercise, we download the information of five ETFs in order to predict future returns by bootstrapping. After we load each ETFs' data we use a helper function, provided by prof. Scott, that provides the returns of each ETFs for each each day in our time interval. 

```{r}
stocks = c("SPY","TLT","LQD","EEM","VNQ")
prices = yahooSeries(stocks, from='2010-01-01', to='2015-08-02')
investment = 100000

YahooPricesToReturns = function(series) 
{
  mycols = grep('Adj.Close', colnames(series))
  closingprice = series[,mycols]
  N = nrow(closingprice)
  percentreturn = as.data.frame(closingprice[2:N,]) / as.data.frame(closingprice[1:(N-1),]) - 1
  mynames = strsplit(colnames(percentreturn), '.', fixed=TRUE)
  mynames = lapply(mynames, function(x) return(paste0(x[1], ".PctReturn")))
  colnames(percentreturn) = mynames
  as.matrix(na.omit(percentreturn))
}

returns = YahooPricesToReturns(prices)
```

With the returns we can now calculate to a degree of accuracy the risk-return trade of for each ETFs, they will come in handy when defining our weighted portfolios. 

```{r}
return_mean = apply(returns, 2, mean)
return_sd = apply(returns, 2, sd)
risk_return = round((return_mean/ return_sd)*100,digits=2)
```
```{r, echo=FALSE}
qplot(return_sd, return_mean, label=names(return_mean), geom=c("point","text"))
```

We have plotted the risk-return relation so it's easier to appreciate and study the differences between all five ETFs. With that in mind we set out to create our three portfolios to study. Our first is a simple even weighted portfolio with all five ETFs in 20% of the wealth. For our second portfolio, the aggressive one, we have decided, based on how volatile equities are compared to fund and by looking at our previous plot, that SPY should get around 45% of our distributed wealth, TLT 10%, LQD 5%, EEM 25% and VNQ 15%. On the contrary, for our safe portfolio we have decided the following weights, SPY 20%, TLT 25%, LQD 50%, EEM 0% and VNQ 5%. We proceed by running bootstrap for each portfolio with their respected weights.

```{r}
even = c(0.2,0.2,0.2,0.2,0.2)
aggre = c(0.45,0.10,0.05,0.25,0.15)
safe = c(0.25,0.25,0.50,0.0,0.05)

# Even Portfolio Bootstrap Simulation
set.seed(101)
even_bootstrap = foreach(i = 1:5000, .combine = 'rbind') %do%
{
  holdings = even*investment
  days = 20
  wealth_tracker = 1:days
  for (today in 1:days)
  {
    todays_returns = resample(returns, 1, orig.ids = FALSE)
    holdings = holdings + holdings*todays_returns
    wealth = sum(holdings)
    wealth_tracker[today] = wealth
  }
  wealth_tracker
}

# Aggresive Portfolio Bootstrap Simulation
set.seed(202)
aggre_bootstrap = foreach(i = 1:5000, .combine = 'rbind') %do%
{
  holdings = aggre*investment
  days = 20
  wealth_tracker = 1:days
  for (today in 1:days)
  {
    todays_returns = resample(returns, 1, orig.ids = FALSE)
    holdings = holdings + holdings*todays_returns
    wealth = sum(holdings)
    wealth_tracker[today] = wealth
  }
  wealth_tracker
}

# Safe Portfolio Bootstrap Simulation
set.seed(303)
safe_bootstrap = foreach(i = 1:5000, .combine = 'rbind') %do%
{
  holdings = safe*investment
  days = 20
  wealth_tracker = 1:days
  for (today in 1:days)
  {
    todays_returns = resample(returns, 1, orig.ids = FALSE)
    holdings = holdings + holdings*todays_returns
    wealth = sum(holdings)
    wealth_tracker[today] = wealth
  }
  wealth_tracker
}

#Even Portfolio 5% Value at Risk
quantile(even_bootstrap[,days],0.05)

#Aggresive Portfolio 5% Value at Risk
quantile(aggre_bootstrap[,days],0.05)

#Safe Portfolio 5% Value at Risk
quantile(safe_bootstrap[,days], 0.05)
```

We see that with the corresponding weights the even portfolio has a 95% chance of ending up losing money and have a final wealth of around 96K, for the aggressive portfolio we lost even more money at a 95% chance with a final wealth of around 94, finally for the safe portfolio we are almost even with the starting wealth with just 2k over it.


#Clustering and PCA

For our third exercise we would like to prove which method is better at separating wine bottles between the red and the whites. Also is the same method able to recreate its accuracy with quality instead. First we read and print out a summary of the wine data set to get a feel of how the data is portrayed. Then we start with clustering to see how well it does dividing the different wines. 

```{r}
wine <- read.csv("wine.csv")
summary(wine)

# Clustering Color
X = wine[,-13]
wine_scaled <- scale(X, center=TRUE, scale=TRUE)

set.seed(101)
cluster_all_prop <- kmeans(wine_scaled, centers=2, nstart=5)

crosstabulate = table(wine$color, cluster_all_prop$cluster)
randIndex(crosstabulate)
```

This result are very appealing, by cross tabulation we see that the clustering method actually got a 92% accuracy at defining what color a wine is based on its 11 properties. We can even see it very clearly in the next plot.

```{r,  echo=FALSE}
par(mfrow=c(1,1))
plotcluster(wine_scaled, cluster_all_prop$cluster)
```

Now lets try PCA to see if it has an accuracy as high as the clustering method. 
```{r}
# PCA on Color
pc2 = prcomp(X, scale=TRUE)
loadings = pc2$rotation
scores = pc2$x
```
```{r, echo=FALSE}
qplot(scores[,1], scores[,2], color=wine$color, xlab='Component 1', ylab='Component 2')
```

Even though we don't have a precise percentage of the accuracy we can see two very distinct groups in the plot, meaning that PCA also did a very good job at predicting it. Now can we say the same about both methods towards figuring out the quality of the wine? 

``` {r}
# Clustering Quality
X = wine[,-(12:13)]
wine_scaled <- scale(X, center=TRUE, scale=TRUE)

set.seed(101)
cluster_all_prop <- kmeans(wine_scaled, centers=7, iter.max=30, nstart=5)
cluster_all_prop$size

crosstabulate = table(wine$quality, cluster_all_prop$cluster)
randIndex(crosstabulate)
```
```{r, echo=FALSE}
plotcluster(wine_scaled, cluster_all_prop$cluster)
```

Just from the cross tabulation result we can see that k mean clustering wont do us any good when trying to identify the wine quality, we can even see it better in the plot they are all pretty much on top of each other not defining a clear group between them. Can PCA do any better? 

```{r}
# PCA on Quality
pc2 = prcomp(X, scale=TRUE)
loadings = pc2$rotation
scores = pc2$x
```
```{r, echo=FALSE}
qplot(scores[,1], scores[,2], color=wine$quality, xlab='Component 1', ylab='Component 2')
```

And no it doesn't, it appears that for both methods determining the quality of the wine with the 11 properties it's very difficult.

#Market segmentation

Now for the last exercise, social media has become a major source of information about costumers for big companies. We got a twitter dataset of a "nameless" company that needs to be analyzed in order to ectract diferent market segments of such company. First as always we load and print a summary of data. Hierachical clustering seems like a good method to approach this problem, and after tweeking it, by trial and error, we ha come to the conclusion that trimming it down to 6 clusters throws the best results.

```{r}
twitter <- read.csv("social_marketing.csv")
summary(twitter)
head(twitter)
names(twitter)

twitter_scaled <- scale(twitter[,-1], center=TRUE, scale=TRUE)  

twitter_distance_matrix = dist(twitter_scaled, method='euclidean')

hier_twitter = hclust(twitter_distance_matrix, method='complete')

interest_clusters = cutree(hier_twitter, k=6)
```

For each individual cluster we have run the same code, that follows: mask the results by clustered against the whole data set to get a subset by cluster. Find the mean for each category and plot those means. Trim the plot base on the most significant categories, name the category

```{r, echo=FALSE}
## First Cluster
mask = which(interest_clusters == 1)
masked_clustered = twitter[mask,-1]
cluster =  apply(masked_clustered, 2 , mean)
qplot(names(cluster), cluster, main = "Cluster #1", xlab = "Category", ylab = "Avg Interest")
cluster = subset(cluster, cluster >= 2)
qplot(names(cluster), cluster, main = "Cluster #1", xlab = "Category", ylab = "Avg Interest")

## Second Cluster
mask = which(interest_clusters == 2)
masked_clustered = twitter[mask,-1]
cluster =  apply(masked_clustered, 2 , mean)
qplot(names(cluster), cluster, main = "Cluster #2", xlab = "Category", ylab = "Avg Interest")
cluster = subset(cluster, cluster >= 1.5)
qplot(names(cluster), cluster, main = "Cluster #2", xlab = "Category", ylab = "Avg Interest")

## Third Cluster
mask = which(interest_clusters == 3)
masked_clustered = twitter[mask,-1]
cluster =  apply(masked_clustered, 2 , mean)
qplot(names(cluster), cluster, main = "Cluster #3", xlab = "Category", ylab = "Avg Interest")
cluster = subset(cluster, cluster >= 3)
qplot(names(cluster), cluster, main = "Cluster #3", xlab = "Category", ylab = "Avg Interest")

## Fourth Cluster
mask = which(interest_clusters == 4)
masked_clustered = twitter[mask,-1]
cluster =  apply(masked_clustered, 2 , mean)
qplot(names(cluster), cluster, main = "Cluster #4", xlab = "Category", ylab = "Avg Interest")
cluster = subset(cluster, cluster >= 3)
qplot(names(cluster), cluster, main = "Cluster #4", xlab = "Category", ylab = "Avg Interest")

## Five Cluster
mask = which(interest_clusters == 5)
masked_clustered = twitter[mask,-1]
cluster =  apply(masked_clustered, 2 , mean)
qplot(names(cluster), cluster, main = "Cluster #5", xlab = "Category", ylab = "Avg Interest")
cluster = subset(cluster, cluster >= 2)
qplot(names(cluster), cluster, main = "Cluster #5", xlab = "Category", ylab = "Avg Interest")

## Six Cluster
mask = which(interest_clusters == 6)
masked_clustered = twitter[mask,-1]
cluster =  apply(masked_clustered, 2 , mean)
qplot(names(cluster), cluster, main = "Cluster #6", xlab = "Category", ylab = "Avg Interest")
cluster = subset(cluster, cluster >= 5)
qplot(names(cluster), cluster, main = "Cluster #6", xlab = "Category", ylab = "Avg Interest")
```

Now by analyzing each trim we can figure out the differente market segments as follows: CLuster #1 --> Fitness/Nutrition, CLuster #2 --> Cooking Photo Enthusiast, CLuster #3 --> Sports, Religious Parents, CLuster #4 --> Cooking Divas, CLuster #5 --> Gossip/Adult , CLuster #6 --> Traveler/Cultured.

